{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oma2ZStyqpQe"
   },
   "source": [
    "# CE-40959: Advanced Machine Learning\n",
    "## HW2 - Optimization-based Meta Learning (100 points)\n",
    "\n",
    "#### Name:  Sepehr Ghobadi\n",
    "#### Student No.:  400211008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zATL8bguriGR"
   },
   "source": [
    "In this notebook, you are going to implement a optimization-based meta learner using the `Omniglot` dataset.\n",
    "\n",
    "Please write your code in specified sections and do not change anything else. If you have a question regarding this homework, please ask it on the Quera.\n",
    "\n",
    "Also, it is recommended to use Google Colab to do this homework. You can connect to your drive using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSsY1Jw7pwZc",
    "outputId": "271d4900-87d7-4077-a2ba-a766ef73ce99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZJ_Hv8Uqoil"
   },
   "source": [
    "## Import Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2NGBSeo0L6Vu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, itertools, copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xabeci_XPcU2"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNHVKqRMM2oD"
   },
   "source": [
    "In Meta-Learning literature and in the meta-training phase, you are given some batches which consist of `support` and `query` sets. you train your model in a way that by using a support set you could predict query set labels correctly.\n",
    "\n",
    "The pioneer of this branch is Model-Agnostic Meta-Learning(MAML). \n",
    "\n",
    "First, we should build the dataset in this way that each batch returns N*(k+k') images. `k` is the number of support images per class and `k'` is the number of query images per class in a batch.\n",
    "\n",
    "The Omniglot data set is designed for developing more human-like learning algorithms. It contains 1623 different handwritten characters from 50 different alphabets. Each of the 1623 characters was drawn online via Amazon's Mechanical Turk by 20 different people.\n",
    "\n",
    "Train and test dataset contains 964 and 659 classes, respectively. Torchvision-based Omniglot dataset is ordered and every 20 images in a row belong to one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZU6nY6ZPDJla"
   },
   "outputs": [],
   "source": [
    "# Meta learning parameters.\n",
    "\n",
    "N = 5\n",
    "support_size = 1\n",
    "query_size = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8bS05XnPe7v"
   },
   "source": [
    "## Prepare dataset (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172,
     "referenced_widgets": [
      "21699c6531584a6b96d5e6645fbb6596",
      "e73123aa2eae4e7c94d1859bdcc58f34",
      "f289e8a847884edf8b3b1f3d0f9dbc63",
      "962d64bdeeaf4f2db84d7e64cc614d8e",
      "2e840d4d4afd49c1a07715f7197c418a",
      "7c14bfb294754c3d97c546fe54c458c1",
      "99ef21eea5ed4d02880d8e0990afc33c",
      "709a28f5dacf408a8bda1c6c6dbf0f74",
      "1e91d7925e024974af759a9957c3c18f",
      "2ababa7aab3d406d8e48296bdfaf5758",
      "eb16cf3d1e774e568e62f722bf0b100a",
      "05018c0433e64908b49f39fddcd9799a",
      "3828b1da11ea45c7ad8e25fd314d2d94",
      "dc16195ea8824f2a9cff27089de06b9d",
      "cb6c851ed41a4d9cb19498636dba6c50",
      "b9fed5497587457f9487208d6a127b36",
      "265ac5c3fd2b45878ecf0f2962fe1a86",
      "d9238947498a486eb9602d22231c4f63",
      "0ca30129fe8b46758699897b1e2adcdf",
      "9dd547953de14fdd84a2ccd18a732637",
      "df4339d9fad24b6c91a203c56bed7c31",
      "1f346186582641af98f615c76084719c"
     ]
    },
    "id": "pMXx6_Py9AhO",
    "outputId": "e56e747d-09eb-45d5-fbd6-e0a8a00161bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip to ./data/omniglot/omniglot-py/images_background.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1084cb6fe29443aa5af1e1cc70aa710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9464212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "     transforms.Resize(28),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = True, transform = transform)\n",
    "test_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = False, transform = transform)\n",
    "\n",
    "train_labels = np.repeat(np.arange(964), 20)\n",
    "test_labels = np.repeat(np.arange(659), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWK0vksv4nVh"
   },
   "source": [
    "To build a dataloader, we should have a class that yields indexes of selected data in the dataset for every iteration and pass it to the `batch_sampler` attribute of dataloader.\n",
    "\n",
    "Complete below code based on this pseudocode:\n",
    "\n",
    "\n",
    "1.   select `N` classes randomly from all classes\n",
    "2.   select `support_size + query_size` images from each classes independently and randomly\n",
    "3.   shuffle dataset indexes, but don't forget to put query indexes at the last of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yODgabjHEY9A"
   },
   "outputs": [],
   "source": [
    "class BatchSampler(object):\n",
    "    '''\n",
    "    BatchSampler: yield a batch of indexes at each iteration.\n",
    "    __len__ returns the number of episodes per epoch (same as 'self.iterations').\n",
    "    '''\n",
    "\n",
    "    def __init__(self, labels, classes_per_it, num_support_samples, num_query_samples, iterations, batch_size):\n",
    "        '''\n",
    "        Initialize the BatchSampler object\n",
    "        Args:\n",
    "        - labels: array of labels of dataset.\n",
    "        - classes_per_it: number of random classes for each iteration\n",
    "        - num_samples: number of samples for each iteration for each class\n",
    "        - iterations: number of iterations (episodes) per epoch\n",
    "        - batch_size: number of batches per iteration\n",
    "        '''\n",
    "        super(BatchSampler, self).__init__()\n",
    "        self.labels = labels\n",
    "        self.classes_per_it = classes_per_it\n",
    "        self.support_sample_per_class = num_support_samples\n",
    "        self.query_sample_per_class = num_query_samples\n",
    "        self.iterations = iterations\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.classes = np.unique(self.labels)\n",
    "        self.indices = np.arange(len(self.labels))\n",
    "\n",
    "    def __iter__(self):\n",
    "        '''\n",
    "        yield a batch of indexes\n",
    "        '''\n",
    "\n",
    "        for it in range(self.iterations):\n",
    "            total_batch_indexes = np.array([])\n",
    "\n",
    "            #################################################################################\n",
    "            #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n",
    "            #################################################################################\n",
    "            # feel free to add/edit initialization part of sampler.\n",
    "            #################################################################################\n",
    "\n",
    "            for _ in range(self.batch_size):\n",
    "                supports = np.array([], dtype=np.int64)\n",
    "                queries = np.array([], dtype=np.int64)\n",
    "                sample_classes = np.random.choice(self.classes , size=self.classes_per_it, replace=False)\n",
    "                for c in sample_classes:\n",
    "                    class_samples = np.random.choice(self.indices[self.labels==c], size=self.support_sample_per_class+self.query_sample_per_class, replace=False)\n",
    "                    supports = np.append(supports, class_samples[0:self.support_sample_per_class])\n",
    "                    queries = np.append(queries, class_samples[self.support_sample_per_class:])\n",
    "                np.random.shuffle(supports)\n",
    "                np.random.shuffle(queries)\n",
    "                total_batch_indexes = np.append(total_batch_indexes, np.append(supports, queries))\n",
    "            #total_batch_indexes = np.reshape(total_batch_indexes, (self.batch_size,-1))    \n",
    "            \n",
    "            #################################################################################\n",
    "            #                                   THE END                                     #\n",
    "            #################################################################################\n",
    "\n",
    "            yield total_batch_indexes.astype(int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vkaRutIUPF4b"
   },
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "batch_size = 32\n",
    "\n",
    "train_sampler = BatchSampler(labels=train_labels, classes_per_it=N,\n",
    "                              num_support_samples=support_size, num_query_samples=query_size, iterations=iterations,\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "test_sampler = BatchSampler(labels=test_labels, classes_per_it=N,\n",
    "                              num_support_samples=support_size, num_query_samples=query_size, iterations=iterations,\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnvAPmPmPh92"
   },
   "source": [
    "## Model (45 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52JCi9o-M2sp"
   },
   "source": [
    "Let's Build our model. the whole model is `ProtoNet` feature extractor which is used in [Prototypical Network paper](https://arxiv.org/abs/1703.05175) but due to the lack of enough computational resources for first part of question, we give you some part of the network as pretraining and only you will do meta-training on the last layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eY3brHqVVXdb"
   },
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels, momentum=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "class Feature_extractor(nn.Module):\n",
    "    '''\n",
    "    source: https://github.com/jakesnell/prototypical-networks/blob/f0c48808e496989d01db59f86d4449d7aee9ab0c/protonets/models/few_shot.py#L62-L84\n",
    "    '''\n",
    "    def __init__(self, x_dim=1, hid_dim=64):\n",
    "        super(Feature_extractor, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(x_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEucQ0e669mc",
    "outputId": "e09b8fb9-2dfd-4176-9a08-75d672fa3d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "feature_extractor = Feature_extractor()\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "feature_extractor.load_state_dict(torch.load('./pretrained_model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8-H1eD9qJXjC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVFRmUfM7UN2"
   },
   "source": [
    "To be specific, you are going to get the features of each image via the feature extraction network and give the output of that as input to your meta-learner. at the end of initialization, you should have initialized your network parameters and have saved them on the given ParameterList for future forward passes.\n",
    "\n",
    "The `Learner` class is a module that initializes your meta-parameters based on your given config as input. the format of config is arbitrary and you should prepare required parameters for initializing your submodules. do a quick look at the modules of meta-network to implement your Learner class.\n",
    "\n",
    "At forwarding pass, you give your input and two optional attributes.\n",
    "\n",
    "1.   **vars**: the default value of this attribute is None and it means that meta-learner will use its own parameters for forwarding pass, but you can give your desired parameters for computing output\n",
    "2.   **bn_training**: if True, batch normalization layers show the same behavior as training time.\n",
    "\n",
    "\n",
    "In the `zero_grad` method, you are going to set the gradient of given parameters as attribute or class parameters (self.vars) to zero.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S7QX9qUnBLSm"
   },
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Learner, self).__init__()\n",
    "\n",
    "        self.cfg = kwargs['config']\n",
    "        # this dict contains all tensors needed to be optimized\n",
    "        self.vars = nn.ParameterList()\n",
    "        # running_mean and running_var\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "        \n",
    "        self.is_freezed = []\n",
    "\n",
    "        #################################################################################\n",
    "        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
    "        #################################################################################\n",
    "        # initialize your meta-network parameters based on given config.\n",
    "        #################################################################################\n",
    "\n",
    "\n",
    "        vars_idx = 0\n",
    "        vars_bn_idx = 0\n",
    "        for idx, params in enumerate(self.cfg):\n",
    "\n",
    "            if \"dim\" in params.keys():\n",
    "                if params['pretrained_params'] is None:\n",
    "                    weights = nn.Parameter(torch.zeros(*params[\"dim\"]))\n",
    "                    bias = nn.Parameter(torch.zeros(params[\"dim\"][0]))\n",
    "                    nn.init.normal_(weights)\n",
    "                    nn.init.normal_(bias)\n",
    "                else:\n",
    "                    weights = nn.Parameter(params['pretrained_params']['weights'])\n",
    "                    bias = nn.Parameter(params['pretrained_params']['bias'])\n",
    "                    \n",
    "                self.vars.append(weights)\n",
    "                self.vars.append(bias)\n",
    "                self.is_freezed.append(params['requires_grad']) # for weight\n",
    "                self.is_freezed.append(params['requires_grad']) # for bias\n",
    "                \n",
    "                vars_idx+=1\n",
    "\n",
    "            if params['layer'] == \"bn\":\n",
    "                if params['pretrained_params'] is None:\n",
    "                    mm = nn.Parameter(torch.zeros(params[\"dim\"][0]), requires_grad=False)\n",
    "                    mv = nn.Parameter(torch.ones(params[\"dim\"][0]), requires_grad=False)\n",
    "                else:\n",
    "                    mm = nn.Parameter(params['pretrained_params']['running_mean'], requires_grad=False)\n",
    "                    mv = nn.Parameter(params['pretrained_params']['running_var'], requires_grad=False)\n",
    "                \n",
    "                self.vars_bn.append(mm)\n",
    "                self.vars_bn.append(mv)\n",
    "                \n",
    "                vars_bn_idx+=1\n",
    "\n",
    "\n",
    "        #################################################################################\n",
    "        #                                   THE END                                     #\n",
    "        #################################################################################\n",
    "\n",
    "\n",
    "    def forward(self, x, vars=None, bn_training=True):\n",
    "\n",
    "        #################################################################################\n",
    "        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
    "        #################################################################################\n",
    "        # compute output of input with given parameters or class parameters\n",
    "        #################################################################################\n",
    "\n",
    "        vars = self.vars if vars is None else vars\n",
    "        vars_bn = self.vars_bn\n",
    "\n",
    "        \n",
    "        modules = {\n",
    "          'conv2d': F.conv2d,\n",
    "          'bn': F.batch_norm,\n",
    "          'relu': F.relu,\n",
    "          'max_pool': F.max_pool2d,\n",
    "          'flatten': torch.flatten,\n",
    "          'linear': F.linear,\n",
    "        }\n",
    "                \n",
    "        vars_idx = 0\n",
    "        vars_bn_idx = 0\n",
    "        for idx, params in enumerate(self.cfg):\n",
    "            kwargs = {\n",
    "                'conv2d': {'input':x, 'weight':vars[2*vars_idx], 'bias':vars[2*vars_idx+1], 'stride':params.get('stride'), 'padding':params.get('padding')},\n",
    "                'bn': {'input':x, 'running_mean':vars_bn[2*vars_bn_idx], 'running_var':vars_bn[2*vars_bn_idx+1], 'weight':vars[2*vars_idx], 'bias':vars[2*vars_idx+1], 'training':bn_training},\n",
    "                'relu': {'input':x},\n",
    "                'max_pool': {'input':x, 'kernel_size': params.get('kernel_size'), 'stride':params.get('stride')},\n",
    "                'flatten': {'input':x, 'start_dim':1},\n",
    "                'linear': {'input':x, 'weight':vars[2*vars_idx], 'bias':vars[2*vars_idx+1]}\n",
    "            }\n",
    "            \n",
    "            x = modules[params['layer']](**kwargs[params['layer']])\n",
    "            \n",
    "            if \"dim\" in params.keys() and 2*(vars_idx+1)!=len(vars):\n",
    "                vars_idx+=1\n",
    "            if params['layer'] == \"bn\" and 2*(vars_bn_idx+1)!=len(vars_bn): # second is for creating kwargs dict problems\n",
    "                vars_bn_idx+=1\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "        #################################################################################\n",
    "        #                                   THE END                                     #\n",
    "        #################################################################################\n",
    "\n",
    "\n",
    "    def zero_grad(self, vars=None):\n",
    "\n",
    "        #################################################################################\n",
    "        #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n",
    "        #################################################################################\n",
    "        # set gradient of given parameters as attribute or class parameters to zero\n",
    "        #################################################################################\n",
    "        with torch.no_grad():\n",
    "            for param in (self.vars if vars is None else vars):\n",
    "                if param.grad is not None:\n",
    "                    param.grad.zero_()\n",
    "        #################################################################################\n",
    "        #                                   THE END                                     #\n",
    "        #################################################################################\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.vars\n",
    "    \n",
    "    def freezed_layers(self):\n",
    "        return self.is_freezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHnhkgpMPk-Z"
   },
   "source": [
    "Now at the `Meta` module, you implement your meta-learner module. you give your all support and query data to your module and the model will update your `Learner` parameters based on MAML-loss.\n",
    "to clarify, you pass your support data to `Learner` and then calculate the loss on them and update your parameters and then continue to update your parameters based on the given number of inner-loop updates and finally calculate the loss on query data and update `Learner` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "b9ebAUChOy68"
   },
   "outputs": [],
   "source": [
    "class Meta(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        super(Meta, self).__init__()\n",
    "\n",
    "        #################################################################################\n",
    "        #                  COMPLETE THE FOLLOWING SECTION (5 points)                   #\n",
    "        #################################################################################\n",
    "        # initialize your meta-learner\n",
    "        #################################################################################\n",
    "\n",
    "        self.inner_loop_lr = kwargs['inner_loop_lr']\n",
    "        self.inner_loop_steps = kwargs['inner_loop_steps']\n",
    "        self.criterion = kwargs['criterion']\n",
    "        self.num_tasks = kwargs['num_tasks']\n",
    "        \n",
    "        self.learner = Learner(config=kwargs['config'])\n",
    "        self.inner_loop_optim = optim.Adam(self.learner.parameters(), lr=self.inner_loop_lr)\n",
    "\n",
    "        #################################################################################\n",
    "        #                                   THE END                                     #\n",
    "        #################################################################################\n",
    "\n",
    "\n",
    "    def forward(self, x_s, y_s, x_q, y_q):\n",
    "\n",
    "        #################################################################################\n",
    "        #                  COMPLETE THE FOLLOWING SECTION (15 points)                   #\n",
    "        #################################################################################\n",
    "        # meta-train your parameters.\n",
    "        #################################################################################\n",
    "\n",
    "        losses, accs, finetuned_weights= [], [], []\n",
    "        \n",
    "        for t in range(self.num_tasks):\n",
    "            inner_loop_weights = self.learner.parameters()\n",
    "            for inner_step in range(self.inner_loop_steps):\n",
    "                logits = self.learner(x_s[t], vars=inner_loop_weights, bn_training=True)\n",
    "                loss = self.criterion(logits, y_s[t])\n",
    "                inner_grad = torch.autograd.grad(loss, inner_loop_weights)\n",
    "                inner_loop_weights = [weight - self.inner_loop_lr*grad*int(is_freezed) for (weight, grad, is_freezed) in zip(inner_loop_weights, inner_grad, self.learner.freezed_layers())]\n",
    "            logits = self.learner(x_q[t], vars=inner_loop_weights, bn_training=True)\n",
    "            losses.append(self.criterion(logits, y_q[t]))\n",
    "            preds = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
    "            accs.append( torch.sum(y_q[t]==preds)/y_q[t].size(0) )\n",
    "            finetuned_weights.append(inner_loop_weights)\n",
    "        \n",
    "        return losses, accs, finetuned_weights\n",
    "\n",
    "\n",
    "\n",
    "        #################################################################################\n",
    "        #                                   THE END                                     #\n",
    "        #################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kp1zVXU2VbMU"
   },
   "outputs": [],
   "source": [
    "def train(model_path, cfg, epochs, train_dataloader, test_dataloader, meta_inner_lr, inner_loop_steps, meta_outer_lr, criterion):\n",
    "    meta_learner = Meta(num_tasks=batch_size, inner_loop_lr=meta_inner_lr, inner_loop_steps=inner_loop_steps, criterion=criterion, config=cfg).to(device)\n",
    "    if model_path is not None:\n",
    "        meta_learner.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    optimizer = optim.Adam(meta_learner.learner.parameters(), lr=meta_outer_lr)\n",
    "    test_acc = 0\n",
    "    for _ in range(epochs):\n",
    "        train_losses, train_accs = [], []\n",
    "        for idx, (x, y) in enumerate(tqdm(train_dataloader)):\n",
    "            x = x.reshape(batch_size,N*(support_size+query_size),1,28,28).to(device)\n",
    "            y = y.reshape(batch_size,N*(support_size+query_size)).to(device)\n",
    "            for task in range(batch_size):\n",
    "                y[task] = y[task].unique(return_inverse=True)[1]\n",
    "            x_s, y_s = x[:,0:support_size*N,:], y[:,0:support_size*N]\n",
    "            x_q, y_q = x[:,support_size*N:,:], y[:,support_size*N:]\n",
    "            batch_losses, batch_accs, batch_finetuned_weights = meta_learner(x_s, y_s, x_q, y_q)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = torch.mean(torch.stack(batch_losses))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append( loss.item() )\n",
    "\n",
    "            acc = torch.mean(torch.stack(batch_accs))\n",
    "            train_accs.append( acc.item() )\n",
    "            # if idx%100 == 0:\n",
    "            #     torch.save(meta_learner.state_dict(), '/content/drive/MyDrive/MAML{}.pt'.format(inner_loop_steps))\n",
    "            #     torch.save(optimizer.state_dict(), '/content/drive/MyDrive/MAMLOPT.pt')\n",
    "            torch.save(meta_learner.state_dict(), '/content/drive/MyDrive/MAMLFULL.pt')\n",
    "        \n",
    "        print(\"train loss: {}.     train acc: {}\".format(np.mean(train_losses), np.mean(train_accs)))\n",
    "        \n",
    "\n",
    "    test_losses, test_accs = [], []\n",
    "    #with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(tqdm(test_dataloader)):\n",
    "      x = x.reshape(batch_size,N*(support_size+query_size),1,28,28).to(device)\n",
    "      y = y.reshape(batch_size,N*(support_size+query_size)).to(device)\n",
    "      for task in range(batch_size):\n",
    "          y[task] = y[task].unique(return_inverse=True)[1]\n",
    "\n",
    "      x_s, y_s = x[:,0:support_size*N,:], y[:,0:support_size*N]\n",
    "      x_q, y_q = x[:,support_size*N:,:], y[:,support_size*N:]\n",
    "\n",
    "      batch_losses, batch_accs, batch_finetuned_weights = meta_learner(x_s, y_s, x_q, y_q)\n",
    "\n",
    "      loss = torch.mean(torch.stack(batch_losses))\n",
    "      test_losses.append(loss.item())\n",
    "      acc = torch.mean(torch.stack(batch_accs))\n",
    "      test_accs.append( acc.item() )\n",
    "\n",
    "    print(\"\\ntest loss: {}.     test acc: {}\".format(np.mean(test_losses), np.mean(test_accs)))\n",
    "    \n",
    "    return np.mean(test_accs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e6UHSbhdK3gY"
   },
   "outputs": [],
   "source": [
    "def get_layer(in_channels, requires_grad, pretrained, feature_extractor=None, layer_idx=None):\n",
    "    if pretrained:\n",
    "        pretrained_params = feature_extractor.state_dict()\n",
    "        pretrained_conv2d = {\n",
    "            'weights' : pretrained_params['encoder.'+str(layer_idx)+'.0.weight'],\n",
    "            'bias' : pretrained_params['encoder.'+str(layer_idx)+'.0.bias']\n",
    "        }\n",
    "        pretrained_bn = {\n",
    "            'weights' : pretrained_params['encoder.'+str(layer_idx)+'.1.weight'],\n",
    "            'bias' : pretrained_params['encoder.'+str(layer_idx)+'.1.bias'],\n",
    "            #'num_batches_tracked' : pretrained_params['encoder.'+str(layer_idx)+'.1.num_batches_tracked']\n",
    "            'running_mean' : pretrained_params['encoder.'+str(layer_idx)+'.1.running_mean'],\n",
    "            'running_var' : pretrained_params['encoder.'+str(layer_idx)+'.1.running_var']\n",
    "        }\n",
    "    else:\n",
    "        pretrained_conv2d, pretrained_bn = None, None\n",
    "        \n",
    "    return [\n",
    "        {'layer':'conv2d', 'dim':[64, in_channels, 3, 3], 'stride':1, 'padding':1, 'requires_grad':requires_grad, 'pretrained_params':pretrained_conv2d},\n",
    "        {'layer':'bn', 'dim':[64], 'requires_grad':requires_grad, 'pretrained_params':pretrained_bn},\n",
    "        {'layer':'relu'},\n",
    "        {'layer':'max_pool', 'kernel_size':2, 'stride':2}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgbrX1ykMYre"
   },
   "source": [
    "## With Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC9bnPrdDI-F"
   },
   "source": [
    "Your Meta-network which you are going to initialize your Learner based on it for first part of question is as follows:\n",
    "\n",
    "\n",
    "1.   **Conv2d layer**: in_channels=64, out_channels:64, kernel_size=3, stride=1, padding=1\n",
    "2.   **BatchNorm2D layer**: out_channels=64\n",
    "3.   **ReLU activation**\n",
    "4.   **Max Pooling layer**: kernel_size = 2, stride = 2\n",
    "5.   **Flatten layer**\n",
    "6.   **Linear layer**: in_features=64, out_features=N (number of classes in meta-learning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aP7sZNrE2Jr"
   },
   "source": [
    "Meta-train **three** different networks with three different inner loop updates=[1, 2, 3]. after some reasonable epochs, plot accuracy of meta-test phase based on inner loop update parameter on each network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "si_-sVXgbYbr"
   },
   "source": [
    "### Train (25 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gf0g22SJ1cb6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#################################################################################\n",
    "#                  COMPLETE THE FOLLOWING SECTION (25 points)                   #\n",
    "#################################################################################\n",
    "# Define your config and initialize model and parameters\n",
    "# prepare your data as input to your model.\n",
    "# train meta-network\n",
    "# get acurracy of model in meta-test phase\n",
    "#################################################################################\n",
    "epochs = 3\n",
    "criterion = F.cross_entropy\n",
    "#inner_loop_steps=3\n",
    "meta_inner_lr = 0.4\n",
    "meta_outer_lr = 0.001\n",
    "\n",
    "\n",
    "\n",
    "cfg = [\n",
    "    *get_layer(in_channels=1, requires_grad=False, pretrained=True, feature_extractor=feature_extractor, layer_idx=0),\n",
    "    *get_layer(in_channels=64, requires_grad=False, pretrained=True, feature_extractor=feature_extractor, layer_idx=1),\n",
    "    *get_layer(in_channels=64, requires_grad=False, pretrained=True, feature_extractor=feature_extractor, layer_idx=2),\n",
    "    *get_layer(in_channels=64, requires_grad=True, pretrained=False),\n",
    "    {'layer':'flatten'},\n",
    "    {'layer':'linear', 'dim':[N, 64], 'pretrained_params':None, 'requires_grad':True}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "#                                   THE END                                     #\n",
    "#################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr5FZp6r1cyZ"
   },
   "source": [
    "Due to lack of computational resources we only train on 1000 episodes per eppoch so accuracies are lower than MAML's paper results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwyVINHPbc5q",
    "outputId": "71c8df20-9a18-49a3-e8ab-52f32b551931"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner steps: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [31:29<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.427586508512497.     train acc: 0.4815904251635075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [31:02<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.8326156954169274.     train acc: 0.68277084928751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 885/1000 [27:38<03:38,  1.90s/it]"
     ]
    }
   ],
   "source": [
    "print(\"inner steps: 1\")\n",
    "test_acc1 = train(None, cfg, epochs, train_dataloader, test_dataloader, meta_inner_lr, 1, meta_outer_lr, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDL27S8EbuwH"
   },
   "source": [
    "Colab Disconnected :))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vn-WpuiISBrW",
    "outputId": "c9f5ed40-e78e-4fc4-feb3-2976019f268f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:12<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5179571034014225.     train acc: 0.8088750213384628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [27:16<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test loss: 0.8222137414216996.     test acc: 0.6891137683987617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = '/content/drive/MyDrive/MAML1.pt'\n",
    "test_acc1 = train(model_path, cfg, 1, train_dataloader, test_dataloader, meta_inner_lr, 1, meta_outer_lr, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1j_A6C6JIGpw",
    "outputId": "2bd717b1-4c7e-47d4-afd1-0633725aa943"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner steps: 2\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [33:28<00:00,  2.01s/it]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.9453941972851754.     train acc: 0.574776677340269\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [33:12<00:00,  1.99s/it]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.7361416172385216.     train acc: 0.7383170998692512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [33:44<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5188516986370086.     train acc: 0.8270425215959549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [32:43<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test loss: 0.83293547976017.     test acc: 0.7102946012616157\n",
      "Test Acc:  0.7102946012616157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"inner steps: 2\")\n",
    "test_acc2 = train(None, cfg, epochs, train_dataloader, test_dataloader, meta_inner_lr, 2, meta_outer_lr, criterion)\n",
    "print(\"Test Acc: \", test_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nW1yqTNCBf6q",
    "outputId": "1965597c-87e3-44c0-ec66-ee0252b9cf2b"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner steps: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [37:12<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.068763453185558.     train acc: 0.6353170975744724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 515/1000 [19:03<17:52,  2.21s/it]"
     ]
    }
   ],
   "source": [
    "print(\"inner steps: 3\")\n",
    "test_acc3 = train(None, cfg, epochs, train_dataloader, test_dataloader, meta_inner_lr, 3, meta_outer_lr, criterion)\n",
    "print(\"Test Acc: \", test_acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colab disconnected again :)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVf1tcUaPDPy",
    "outputId": "b504a42b-b404-41e3-b8d8-a8693d5f2e1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [55:19<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3412625925441583.     train acc: 0.8927080799738566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [38:32<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test loss: 0.5302745303809643.     test acc: 0.8257658569812775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = '/content/drive/MyDrive/MAML3.pt'\n",
    "test_acc3 = train(model_path, cfg, 1, train_dataloader, test_dataloader, meta_inner_lr, 3, meta_outer_lr, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5X-lOSBN15I"
   },
   "source": [
    "### Plot (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hDTwQqmNnX_"
   },
   "source": [
    "Plot accuracy of meta-test phase based on inner loop update parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "4FDQZ0WoNCOS",
    "outputId": "b9334a79-8ee2-4d87-e629-7742e8377665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6891137683987617, 0.7102946012616157, 0.8257658569812775]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inner_loop_steps = [1, 2, 3]\n",
    "#exectimes_hour = [2.02, 2.20, 2.53]\n",
    "test_accs = [test_acc1, test_acc2, test_acc3]\n",
    "print(test_accs)\n",
    "plt.plot(inner_loop_steps, test_accs)\n",
    "#plt.plot(inner_loop_steps, exectimes_hour)\n",
    "plt.xlabel(\"Inner Loop Steps\")\n",
    "plt.xticks(inner_loop_steps, inner_loop_steps)\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "_ = plt.title(\"MAML Meta-tets Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTILlHKIIGfD"
   },
   "source": [
    "## Without Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTDVBPWqOeNj"
   },
   "source": [
    "### Train (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyYmPMOSN66S"
   },
   "source": [
    "Now also add feature extractor network to your meta-network and repeat the same procedure like above cells just for inner loop update = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ALu1EEDQ0RQ",
    "outputId": "8518d98a-58e0-40d4-e721-8a5fa8893140"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [32:17<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.257792637050152.     train acc: 0.5045220929980277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [32:08<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.7130178537368774.     train acc: 0.7318445996046067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [32:04<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.49481831380724906.     train acc: 0.8198312706947327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [27:44<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test loss: 0.7104940785765648.     test acc: 0.7330891833305359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#################################################################################\n",
    "#                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
    "#################################################################################\n",
    "# Define your config and initialize model and parameters\n",
    "# prepare your data as input to your model.\n",
    "# train meta-network\n",
    "# get acurracy of model in meta-test phase\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "criterion = F.cross_entropy\n",
    "inner_loop_steps=1\n",
    "meta_inner_lr = 0.4\n",
    "meta_outer_lr = 0.001\n",
    "\n",
    "\n",
    "\n",
    "cfg = [\n",
    "    *get_layer(in_channels=1, requires_grad=True, pretrained=True, feature_extractor=feature_extractor, layer_idx=0),\n",
    "    *get_layer(in_channels=64, requires_grad=True, pretrained=True, feature_extractor=feature_extractor, layer_idx=1),\n",
    "    *get_layer(in_channels=64, requires_grad=True, pretrained=True, feature_extractor=feature_extractor, layer_idx=2),\n",
    "    *get_layer(in_channels=64, requires_grad=True, pretrained=False),\n",
    "    {'layer':'flatten'},\n",
    "    {'layer':'linear', 'dim':[N, 64], 'pretrained_params':None, 'requires_grad':True}\n",
    "]\n",
    "\n",
    "test_acc = train(None, cfg, epochs, train_dataloader, test_dataloader, meta_inner_lr, inner_loop_steps, meta_outer_lr, criterion)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "#                                   THE END                                     #\n",
    "#################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qSBg8MQO9aF"
   },
   "source": [
    "### Report (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylzdpCPfOZSJ"
   },
   "source": [
    "Report accuracy of meta-test phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpDr19S-_lud",
    "outputId": "bb3f673a-8b36-4559-b29e-87c33cf00eaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7330891833305359"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVX1qagbRGvV"
   },
   "source": [
    "## Compare and explain Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOKygCh_Rhkc"
   },
   "source": [
    "Answer:\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl",
    "id": "fb2aUT1ARivE"
   },
   "source": [
    "همانطور که دیده شد با افزایش تعداد مراحل لوپ داخلی دقت مدل افزایش یافت (می توان حدس زد افزایش غیر خطی نیز باشد). از لحاظ شهودی نیز باید اینگونه باشد زیرا هدف در MAML یافتن نقطه اولیه ای است که بعد از اداپت شدن به تسک جدید با دیتای ترین آن تسک روی دیتای تست ان عملکرد خوبی داشته باشد. حال اگر این فرآیند اداپتیشن یک مرحله باشد نقطه شروع اولیه باید با نقطه مناسب همه تسک های متا-تست فقط یک قدم فاصله داشته باشد که بسته به ماهیت تسک ها ممکن است نتوان نقطه خوبی با این مشخصات یافت. اما اگر مراحل داخلی افزایش یابد یافتن یک نقطه اولیه مناسب می تواند روی تسک های با ماهیت متفاوت ریلکس تر باشد زیرا میتوان چند قدم بهینه سازی داخلی انجام داد. اما از طرف دیگر افزایش مراحل بهینه سازی اداپتیشن هم زمان متا-یادگیری را و هم امکانات محاسباتی را (اینجا هم احتمالا غیر خطی) افزایش می دهد. زیرا باید تعداد مراحل داخلی رو همه تسک ها افزایش یافته و از طرفی برای محاسبه گرادیان متا-پارامتر ها بعد از اداپتیشن باید تمام مسیر بهینه سازی داخلی را نگه داشت و متا-گرادیان را از آن عبور داد.\n",
    "\n",
    "همچنین انتظار میرفت متا-آموزش کل شبکه واضحا به نتایج بهتری دست یابد زیرا در حالت متا-یادگیری کل شبکه شبکه آموزش دیده شده backbone نیز متا-آموزش داده شده و finetune می شود تا فیچر های مناسب تری را برای توزیع تسک های مساله حال حاضر ارائه دهد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MAML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05018c0433e64908b49f39fddcd9799a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3828b1da11ea45c7ad8e25fd314d2d94",
       "IPY_MODEL_dc16195ea8824f2a9cff27089de06b9d",
       "IPY_MODEL_cb6c851ed41a4d9cb19498636dba6c50"
      ],
      "layout": "IPY_MODEL_b9fed5497587457f9487208d6a127b36"
     }
    },
    "0ca30129fe8b46758699897b1e2adcdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e91d7925e024974af759a9957c3c18f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f346186582641af98f615c76084719c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21699c6531584a6b96d5e6645fbb6596": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e73123aa2eae4e7c94d1859bdcc58f34",
       "IPY_MODEL_f289e8a847884edf8b3b1f3d0f9dbc63",
       "IPY_MODEL_962d64bdeeaf4f2db84d7e64cc614d8e"
      ],
      "layout": "IPY_MODEL_2e840d4d4afd49c1a07715f7197c418a"
     }
    },
    "265ac5c3fd2b45878ecf0f2962fe1a86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ababa7aab3d406d8e48296bdfaf5758": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e840d4d4afd49c1a07715f7197c418a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3828b1da11ea45c7ad8e25fd314d2d94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_265ac5c3fd2b45878ecf0f2962fe1a86",
      "placeholder": "​",
      "style": "IPY_MODEL_d9238947498a486eb9602d22231c4f63",
      "value": ""
     }
    },
    "709a28f5dacf408a8bda1c6c6dbf0f74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c14bfb294754c3d97c546fe54c458c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "962d64bdeeaf4f2db84d7e64cc614d8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ababa7aab3d406d8e48296bdfaf5758",
      "placeholder": "​",
      "style": "IPY_MODEL_eb16cf3d1e774e568e62f722bf0b100a",
      "value": " 9464832/? [00:00&lt;00:00, 17259019.09it/s]"
     }
    },
    "99ef21eea5ed4d02880d8e0990afc33c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dd547953de14fdd84a2ccd18a732637": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9fed5497587457f9487208d6a127b36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb6c851ed41a4d9cb19498636dba6c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df4339d9fad24b6c91a203c56bed7c31",
      "placeholder": "​",
      "style": "IPY_MODEL_1f346186582641af98f615c76084719c",
      "value": " 6463488/? [00:00&lt;00:00, 18073100.16it/s]"
     }
    },
    "d9238947498a486eb9602d22231c4f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc16195ea8824f2a9cff27089de06b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ca30129fe8b46758699897b1e2adcdf",
      "max": 6462886,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9dd547953de14fdd84a2ccd18a732637",
      "value": 6462886
     }
    },
    "df4339d9fad24b6c91a203c56bed7c31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e73123aa2eae4e7c94d1859bdcc58f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c14bfb294754c3d97c546fe54c458c1",
      "placeholder": "​",
      "style": "IPY_MODEL_99ef21eea5ed4d02880d8e0990afc33c",
      "value": ""
     }
    },
    "eb16cf3d1e774e568e62f722bf0b100a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f289e8a847884edf8b3b1f3d0f9dbc63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_709a28f5dacf408a8bda1c6c6dbf0f74",
      "max": 9464212,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e91d7925e024974af759a9957c3c18f",
      "value": 9464212
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
