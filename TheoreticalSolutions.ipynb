{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "piano-communist",
   "metadata": {},
   "source": [
    "# سوالات نظری تمرین سری دوم یادگیری ماشین پیشرفته\n",
    "## سپهر قبادی - ۴۰۰۲۱۱۰۰۸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-separation",
   "metadata": {},
   "source": [
    "__** اگر خانه هایی که با latex نوشته شده اند رندر نشده اند کافی است یکبار خانه را ادیت و اجرا کنید **__\n",
    "\n",
    "__** ممکن است در فایل html نوشته ا راست چین نباشند. در این صورت نوت بوک را باز کنید**__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-southwest",
   "metadata": {},
   "source": [
    "# سوال ۱\n",
    "\n",
    "الف)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-thomas",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\phi = arg\\min_{\\phi^\\prime} (\\mathcal L(\\phi^\\prime, \\mathcal S) + \\frac{\\lambda}{2} \\lVert \\phi^\\prime - \\theta \\rVert ^ 2) \\\\\n",
    "\\Rightarrow \\nabla_{\\phi^\\prime} (\\mathcal L(\\phi^\\prime, \\mathcal S) + \\frac{\\lambda}{2} \\lVert \\phi^\\prime - \\theta \\rVert ^ 2)|_{\\phi^\\prime = \\phi} = 0 \\ \\ \\ \\Rightarrow \\ \\ \\  \\nabla_{\\phi} \\mathcal L(\\phi, \\mathcal S) + \\lambda \\mathcal I (\\phi-\\theta) = 0 \\\\\n",
    "\\Rightarrow \\phi = \\theta - \\frac{1}{\\lambda} \\nabla_{\\phi} \\mathcal L(\\phi, \\mathcal S) \\ \\ \\ \\Rightarrow \\ \\ \\ \\frac{\\partial \\phi}{\\partial \\theta} = \\mathcal I - \\frac{1}{\\lambda} \\frac{\\partial}{\\partial \\theta} \\nabla_{\\phi} \\mathcal L(\\phi, \\mathcal S)    =   \\mathcal I - \\frac{1}{\\lambda} \\frac{\\partial \\phi}{\\partial \\theta}\\frac{\\partial}{\\partial \\phi} \\nabla_{\\phi} \\mathcal L(\\phi, \\mathcal S) = \\mathcal I - \\frac{1}{\\lambda} \\frac{\\partial \\phi}{\\partial \\theta} \\nabla_{\\phi}^2 \\mathcal L(\\phi, \\mathcal S) \\\\\n",
    "\\Rightarrow \\frac{\\partial \\phi}{\\partial \\theta}(\\mathcal I + \\frac{1}{\\lambda}\\nabla_{\\phi}^2 \\mathcal L(\\phi, \\mathcal S)) = \\mathcal I \\ \\ \\ \\Rightarrow \\ \\ \\ \\frac{\\partial \\phi}{\\partial \\theta} = (\\mathcal I + \\frac{1}{\\lambda}\\nabla_{\\phi}^2 \\mathcal L(\\phi, \\mathcal S))^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-louisiana",
   "metadata": {},
   "source": [
    "ب) تفاوت مشتق مرتبه دوم حاصل از استفاده از تابع ارائه شده به عنوان inner-loop با معادله (۴) در این است که Hessian بدست آمده در نقطه نهایی بهینه سازی ارزیابی شده است و فقط به حاصل نهایی الگوریتم وابسته است اما معادله ۴ در نقطه شروع ارزیابی شده و به مقدار اولیه وابسته است. مشکلی که معادله ۴ دارد این است که به دلیل وابستگی محاسبه مشتق دوم در نقطه شروع، در صورتی که الگوریتم inner-loop یک بهینه سازی تکرار شونده باشد برای محاسبه ی گرادیان و انتقال به outer-loop باید تمام مقادیر در طی مسیر الگوریتم داخل ذخیره شوند تا بتوان گرادیان را از روی آن عبور داد. اما مشتق دوم معادله جدید فقط به حاصل نهایی الگوریتم وابسته است نه مسیر طی شده. به عبارتی این الگوریتم محاسبه گرادیان inner-loop به outer-loop را از فرآیند بهینه سازی داخلی کاملا تفکیک کرده و فقط به نتیجه بهینه سازی داخلی وابستگی دارد.\n",
    "\n",
    "مزیت این روش نسبت به MAML این است که حالا می توان بدون نگرانی محاسباتی بهینه سازی تکرار شونده داخلی را چندین مرحله تکرار کرد. این مزیت می تواند متا-یادگیری را در دیستریبیوشن وظایفی که ممکن است زیاد مشابه نباشند تسهیل کند زیرا در این مسائل احتمالا مراحل کم بهینه سازی داخلی در MAML که به دلیل محدودیت های محاسباتی است نتواند به نتایج خوبی برسد. همچنین واضحا روش ارائه شده به دلیل عدم وابستگی به مسیر بهینه سازیی داخلی از لحاظ هزینه های زمانی و حافظه ای محاسباتی (مخصوصا حافظه) نسبت به MAML برتری دارد. همچنین با توجه به اینکه گرادیان داخل به خارج در الگوریتم جدید با فرض اپتیمال بودن نتیجه نهایی بهینه سازی محاسبه شده است، اگر واقعا بهینه سازی داخلی به تعداد کافی تکرار شود احتمالا مشتق \"تقریبی\" محاسبه شده نسبت به MAML (حتی در تعداد مراحل مشابه) دقیق تر باشد. البته ممکن است بسته به مقدار پارامتر $\\lambda$ محدودیت الگوریتم جدید بیش از حد باشد و دقت آن را کاهش دهد.\n",
    "\n",
    "ج)مانند روال معمول متا یادگیری بر پایه بهینه سازی، در هر مرحله روی یک وظیفه با مقدار دهی اولیه ای برابر با مقدار متا-پارامتر ها فرآیند یادگیری را شروع کرده و خروجی $\\mathcal Alg$ را بدست می آوریم(همان $\\phi$ ). اما در این روش نیازی به بازگشت دادن گرادیان در طی مسیر الگوریتم inner-loop نیست. در نقطه پایانی لوپ داخلی ابتدا مقدار گرادیان روی داده های ساپورت را محاسبه می کنیم (همان $\\frac{\\partial \\phi}{\\partial \\theta}$ که در قسمت الف فرمول آن بدست آمد) و سپس طبق قاعده زنجیره ای که در معادله (۳) صورت سوال بدست آمد گرادیان لوپ داخلی ($\\frac{\\partial \\phi}{\\partial \\theta}$)را در گرادیان لاس روی داده های کوئری در نقطه پایانی لوپ داخلی ($\\nabla_{\\phi} \\mathcal L(\\phi, \\mathcal Q)$) ضرب میکنیم. در پایان متاپارامتر های اولیه ی تسک را با حاصلضرب این ۲ گرادیان که همان متا-گرادیان است آپدیت میکنیم. (البته اگر روی یک بچ از تسک ها متا-ترینینگ را انجام دهیم با میانگین متا-گرادیان ها آپدیت می کنیم)\n",
    "\n",
    "البته در فرمول های تئوری قسمت الف فرض شد که $\\phi$ که حاصل بهینه سازی داخلی است و از فرمول ها بدست می آید جواب دقیق و  بهینه سراسری تابع $\\mathcal Alg$ است. اما محاسبه آن برای توابع پیچیده به صورت جواب دقیق ممکن نیست و ما می توانیم به صورت بهینه سازی تکرار شونده آن را تقریب بزنیم. همچنین قاعدتا تعداد پارامتر های مدل به قدری زیاد خواهد بود که محاسبه ماتریس معکوس در قسمت الف ممکن نباشد. برای تقریب زدن ماتریس معکوس می توان از روش های BFGS یا Quasi-Newton استفاده کرد. همچنین می توان به جای تقریب زدن معکوس ماتریس هشن و ضرب آن تقریب در گرادیان لاس روی داده های کوئری می توان به طور کامل حاصل ضرب معکوس ماتریس هشن در گرادیان لاس روی داده های کوئری را تقریب زد که احتمالا دقت کلی متا-گرادیان را کاهش می دهد اما همانطور که در صفحه ۳ مقاله MAML اشاره شده است محاسبه حاصل ضرب های Hessian-Vector راه حل های محاسباتی مناسب دارند و فریمورک های استاندارد مانند تنسورفلو نیز ایین محاسبات را به راحتی پشتیبانی می کنند. در MAML برای اینکه از First-Order Optimization لوپ داخلی دقیق تری داشته باشیم ازین حاصلضرب ها استفاده شده و ما میتوانیم به کمک همین روش محاسبه مستقیم ماتریس معکوس هشن را دور بزنیم."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-drilling",
   "metadata": {},
   "source": [
    "# سوال ۲\n",
    "\n",
    "الف)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-hardware",
   "metadata": {},
   "source": [
    "همانطور که می دانیم در متا-لرنینگ نیاز است تا اطلاعات و ارور های اداپتیشن از لوپ داخلی به متالرنر انتقال یافته تا متا-پارامتر ها آپدیت شوند. اگر فرآیند اداپتیشن در لوپ داخلی پیچیده یا چند مرحله ای باشد، عبور دادن گرادیان ها ممکن است کند و یا حتی غیر ممکن باشد. مثلا در MAML می دانیم لووپ داخلی یک اپتیمیزیشن است و جون برای عبور گرادیان از این فرآیند باید مشتقات مرتبه دوم را نگه داری کرد نمی توان لوپ داخلی را در مسائل بزرگ از چند مرحله بیشتر تکرار کرد. در الگوریتم های استفاده شده در این مقاله نیز ممکن است این مشکل بوجود بیاید. زیرا اگر تعداد نمونه ها و فیچر ها زیاد باشند بدست اوردن یک جواب با فرم بسته بهه صورت مستقیم ممکن نیست از لحاظ محاسباتی. در نتیجه باید از روش های تکرار شونده مانند گرادیان نزولی یا نیوتن استفاده کرد. اگر نییاز به چند مرحله تکرار باشد عبور گرادیان از فرآیند الگوریتم داخلی به لوپ خارجی ممکن است از لحاظ محاسباتی و حافظه ای بسیار سنگین باشد. اما روش های پروتوتایپی یا نزدیک ترین همسایه این مشکل را ندارند زیرا معمولا لوپ داخلی و فرآیند اداپتیشن آنها یک محاسبات خطی رو داده های ساپورت است (مانند میانگین گیری یا محاسبه فاصله دیتای کوئری به دیتا های ساپورت) و از لحاظ محاسباتی بسیار سبک هستند اما مشکلی که دارند ضعف در جنرالیزیشن آنهاست زیرا اساسا مدل متا-ترین شده آنها از دیتای ساپورت برایی اداپت شدن به تسک جدید استفاده نمی کند و چون معمولا متالرنینگ در شرایطی با دیتای محدود به کار گرفته می شود، در صورتی که نمونه های آوتلایر در دیتای ساپورت وجود داشته باشد استفاده از فضای نمایش و تابع فاصله متالرن شده و دیتای کم ساپورت به عنوان پروتوتایپ قابلیت تعمیم پذیری الگوریتم ها را کاهش می دهد.\n",
    "\n",
    "ب) همانطور که گفته شد در نگاه اول حل فرم بسته به دلیل زمان درجه ۲ نسبت به سایز امبدینگ ها و همچنین حل فرم تکرار شونده به دلیل لزوم ذخیره مشتقات میانی با ابعاد بالا غیر ممکن است. اما با استفاده از فرمول Woodbury معرفی شده در مقاله (و قسمت بعدی سوال) می توان محاسبات را به فرمم درجه ۲ به نسبت تعداد داده ها و زمان خطی به نسبت اندازه امبدینگ ها کاهش داد. با توجه به اینکه در ستینگ few-shot تعداد داده ها بسیار اندک است، این تکنیک حجم محاسبات و یا حافظه مورد نیاز را بسییار کاهش می دهد. در این مقاله به کمک تکنیک گفته شده برای استفاده از دسته بند Ridge-Regression یک راه حل عملیاتی برای با روش  فرم بسته و برای Logistic-Regression  یک راه حل عملیاتی با روش تکرار شونده ارائه می شود.\n",
    "\n",
    "ج) همانطور که لم ۲ صفحه ۹ مقاله [Max Welling. The Kalman Filter. Lecture Note.] ذکر شده است رابطه زیر برای ماتریس های مثبت و معین P و R برقرار است:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-elevation",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "(P^{-1}+B^TR^{-1}B)^{-1} B^TR^{-1} = PB^T(BPB^T+R)^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-capacity",
   "metadata": {},
   "source": [
    "با قرار دادن $P=\\frac{1}{\\lambda}I$ و $R=I$ و $B=X$ و توجه به اینکه ماتریس های P و R مثبت معین هستند داریم:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-charity",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "((\\frac{1}{\\lambda}I)^{-1}+X^TX)^{-1} X^T = {\\bf (\\lambda I+X^TX)^{-1} X^T} = \\frac{1}{\\lambda}IX^T(X(\\frac{1}{\\lambda}I)X^T + I)^{-1} = \\frac{1}{\\lambda}IX^T\\lambda \\lambda^{-1}(\\frac{1}{\\lambda}XX^T + I)^{-1} = {\\bf X^T (XX^T + \\lambda I)^{-1} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-bargain",
   "metadata": {},
   "source": [
    "که با ضرب از راست Y در تساوی بالا به تساوی نوشته شده در صورت سوال می رسیم. همانطور که میدانیم و در فرمول شماره ۳ مقاله ذکر شده نوشته شده است اگر الگوریتم داخلی را Ridge-Regression در نظر بگیریم فرم بسته جواب آن به شکل زیر است:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-corrections",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "Λ(Z) = arg\\min_{W} \\ \\  \\lVert XW−Y \\rVert^2 + \\lambda \\lVert W \\rVert^2 =(X^TX+\\lambda I)^{−1}X^TY,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-feelings",
   "metadata": {},
   "source": [
    "د) با جاگذاری معادل فرم بسته عبارت بالا که در قسمت قبل به دست آمد محاسبات بسیار کاهش می یابد. زیرا در فرم اولیه یک عبارت $X^TX$ وجود دارد که از بعد $d*d$ است اما در فرم ثانویه این عبارت با $XX^T$ جایگزین شده است که ابعاد آن $n*n$ است. نگه داری و انجام عملیات معکوس و ... روی فرم دوم در مسائلی که تعداد داده ها (n) کم است و معمولا هم ابعاد امبدینگ (d) برای داده هایی از جنس تصویر و ... بالا است بسیار از لحاظ محاسباتی و زمانی بهینه تر است زیرا فرم ثانویه به نسبت سایز امبدینگ خطی است در حالیی که فرم اولییه درجه ۲ بود.\n",
    "\n",
    "ه) روش نیوتن برای بدست آوردن ریشه های توابع مشتق پذیر استفاده می شود و می توان از آن برای بدست آوردن نقطه صفر مشتق یک تابع که همان اپتیمم تابع است استفاده کرد. شرایط خاصی برای استفاده از روش نیوتن وجود دارد اما اگر شرایط برقرار باشند این روش بسیار سریعتر است. یکی از شروط این است که مشتق دوم(هشن) تابع معکوس پذیر و مثبت معین باشد که این شرایط وقتی برقرار است که تابع اکیدا محدب باشد. وجود این شرایط همانطور که در مقاله ذکر شده است روش نیوتن را برای مدل های خطی و توابع هزینه محدب مناسب می سازد.  در این روش از بسط مرتبه دوم یک تابع به شکل زیر استفاده می شود:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-warrior",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "f_t(\\theta) = f_t + g^{T}_{t} (\\theta − \\theta_t) + 1/2(\\theta − \\theta_t)^T H_t(\\theta − \\theta_t) = \\theta^TA\\theta + b^T\\theta +c  \\ \\ \\ \\ \\ \\ \\text{where} \\ \\ \\ A=1/2 H_t, \\ \\ b = g_t - H_t\\theta_t, \\ \\ c=f_t-g_{t}^T\\theta_t + 1/2\\theta_{t}^{T}H_t\\theta_t\n",
    "\\min(\\theta^TA\\theta + b^T\\theta +c) = \\theta = -\\frac{1}{2}A^{-1}b = \\theta_t - H_{t}^{-1}g_{t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-independence",
   "metadata": {},
   "source": [
    "البته معمولا به جای محاسبه $H^{-1}g$ معادله $Hd=g$ حل شده و از d به عنوان اپدیت استفاده می شود.\n",
    "\n",
    "و)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-stupid",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "NLL(w) = \\sum_{i=1}^{N} \\log(1+\\exp(-y_iw^Tx_i)) + \\frac{1}{2} \\lambda \\lVert w \\rVert^2 \\\\\n",
    "\\Rightarrow g = \\frac{d}{dW} f(w) = \\sum _{i=1}^{N}(\\sigma(w^Tx_i) - y_i)x_i + \\lambda \\lVert w \\rVert = X^T(\\sigma(w^TX)-Y) + \\lambda \\lVert w \\rVert = X^TB + \\lambda \\lVert w \\rVert \\\\\n",
    "\\Rightarrow H = \\frac{d}{dW} g(w)^T = \\sum_{i=1}^{N} (\\frac{\\partial}{\\partial w} \\sigma(w^Tx_i))x_{i}^T + \\lambda I= \\sum_{i=1}^{N} \\sigma(w^Tx_i)(1-\\sigma(w^Tx_i))x_i x_{i}^T + \\lambda I = X^TAX + \\lambda I\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-country",
   "metadata": {},
   "source": [
    "حال با جاگذاری در رابطه نیوتن داریم:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-machinery",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "w_{t+1} = w_t - H^{-1}g_t = w_t - (X^TA_tX+\\lambda I)^{-1}(X^TB_t+\\lambda w_t ) = (X^TA_tX+\\lambda I)^{-1}[(X^TA_tX+\\lambda I)w_t - X^TB_t - \\lambda w_t] = (X^TA_tX+\\lambda I)^{-1}[X^TA_tXw_t+ \\lambda w_t - X^TB_t - \\lambda w_t] = (X^TA_tX+\\lambda I)^{-1}X^T[A_tXw_t - B_t]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-calgary",
   "metadata": {},
   "source": [
    "# سوال ۳\n",
    "\n",
    "الف) با توجه به اینکه یادگیر پایه یک svm است، متا پاارامتر ها که پارامتر های backbone هستند به گونه ای تعیین می شوند که وزن های svm بدست آمده بعد از آموزش روی فیچر های بدست آمده بهترین عملکرد را روی داده تست داشته باشند. یعنی پارامتر های سریع، وزن های کلاس های مختلف در svm هستند که از حل بهینه سازی  svm روی فیچر های استخراج شده از داده های متاآموزش بدست می آیند. بهینه سازی svm که پارامتر های سریع را می دهد به شکل زیر است :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-variable",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\phi = \\mathcal Alg(D_train, \\theta) = arg \\min_{w_k, \\zeta_i} \\frac{1}{2} \\sum_k \\lVert w_k \\rVert_{2}^{2} + C\\sum_n \\zeta_n \\ \\ \\ \\ \\text{ s.t. } \\ \\ \\ w_{y_n}f_{\\theta}(x_n) - w_{k}f_{\\theta}(x_n) \\geq 1 - \\delta_{y_n, k} - \\zeta_n  \\ \\ \\ \\forall k,n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-contract",
   "metadata": {},
   "source": [
    "که $w_k$ وزن های svm برای کلاس k ام، $\\zeta_n$ متغیر های اسلک soft-margin svm و $\\delta$ تابع دیراک و $f_\\theta$ شبکه backbone با متا پارمتر های $\\theta$ هستند. حال فرم دوگان را می نویسیم: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-attention",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\mathcal L = \\frac{1}{2} \\sum_k \\lVert w_k \\rVert_{2}^{2} + C\\sum_n \\zeta_n + \\sum_{n,k} \\alpha_{n}^{k} [ -w_{y_n}f_{\\theta}(x_n) + w_{k}f_{\\theta}(x_n) + 1 - \\delta_{y_n, k} - \\zeta_n ] \\\\ \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-courtesy",
   "metadata": {},
   "source": [
    "با جاگذاری و حذف همه متغیر ها غیر از متغیر های دوگان قسمت ۲.۲ و ۲.۳ مقاله [Solving multiclass support vector machines with LaRank, J. Weston] میتوان فرم دوگان را بدست آورد:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-lecture",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\max_{\\beta} [ -\\frac{1}{2}\\sum_{i,j,y,\\bar y} \\beta_{i}^{y} \\beta_{j}^{\\bar y}<\\phi(x_i,y), \\phi(x_j, \\bar y)> + \\sum_n \\beta_{n}^{y_n} ] \\ \\ \\ \\ \\ \\text{where} \\beta_{i}^{y} = -\\alpha_{i}^{y} \\ \\ \\text{if} \\  y!=y_i \\ \\ \\text{else} \\ \\ \\sum_{\\bar y != y_i} \\alpha_{i}^{\\bar y} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-kelly",
   "metadata": {},
   "source": [
    "با جایگذاری $\\beta$ و استفاده از Kernel Factorization به شکل $ <\\phi(x_i,y), \\phi(x_j, \\bar y)> = K(x_i,x_j)\\delta(y, \\bar y) = f_{\\theta}(x_i)f_{\\theta}(x_j)\\delta(y, \\bar y) $ در رابطه بالا داریم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-zoning",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\max_{\\alpha^k} [ -\\frac{1}{2}\\sum_k \\lVert w_k(\\alpha^k) \\rVert_{2}^{2} + \\sum_n \\alpha_{n}^{y_n} ]  \\ \\ \\ \\text{where}  \\ \\ \\ w_k(\\alpha^k) = \\sum_k \\alpha_{n}^{k} f_{\\theta}(x_n)\\\\\n",
    "s.t. \\ \\ \\ \\alpha_{n}^{y} \\leq C\\delta(y,y_n) \\ \\ \\ \\text{and}\\ \\ \\ \\ \\sum_k \\alpha_{k}^{n} = 0 \\ \\ \\ \\ \\ \\forall n,y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-extreme",
   "metadata": {},
   "source": [
    "ب) همانطور که در معادله  ۵ مقاله آورده شده است شرایط kkt به شکل زیر هستند: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-outreach",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "f(\\theta, x) \\leq 0 \\\\\n",
    "h(\\theta, x) = 0 \\\\\n",
    "\\lambda_i f_i(\\theta, x) = 0 \\\\\n",
    "\\nabla_x L(x, \\lambda, v, \\theta) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-double",
   "metadata": {},
   "source": [
    "همانطور که در مقاله گفته شده است می توان اپتیمیزیشن را با یافتن نقطه زینی معادله لاگرانژ ۶ مقاله نوشت. می توان نشان داد که هم زمان $\\lambda_i$ و $f_i$ صفر نمی شوند [Onthe Differentiability of the Solution to Convex Optimization Problems, Barrat]. پس برای $\\lambda_i \\geq 0$ نامساوی اول بدیهی می شود و می توان جواب بهینه را با مساوی صفر قرار دادن ۳ شرط دیگر به شکل $g(\\theta, \\lambda, v, z)$ نوشته شده در عبارت ۷ مقاله بدست آورد.\n",
    "\n",
    "حال فرض کنیم بهینه سازی حل شده است و $ g(\\bar x, \\bar \\theta) = 0 $ برای یک $\\bar x = (x, \\lambda, v)$  . برای اینکه گرادیان $\\theta$ پیدا شده به نسبت ورودی ها را پیدا کنیم و آن گرادیان را به شبکه backbone برگردانیم برای آپدیت متا پارامتر ها باید گرادیان ها را از فرآیند بهینه سازی داخلی نوشته شده در بالا با قرار دادن بهینه سازی svm خود در شروط بدست آورد. در حالت عادی برای بدست آوردن این گرادیان باید روی تمام مراحل بهینه سازی داخلی backproppagation انجام داد. اما در اینجا با اعمال implicit function theorem روی شرایط بدست آمده در بالا یک فرم بسته وابسته به پارامتر اپتیمال نهایی برای گرادین بدست می آوریم. به طور خلاصه طبق قضیه ift با در نظر گرفتن شراط مشتق پذیری در نقطه بهینه که در این مساله برقرار است، برای یک تابع ۲ متغیره اگر یکی از آنها را ورودی در نظر بگیریم می توان مشتق پارامتر بهینه تابع را به نسبت ورودی را با ارزیابی مشتق تابع در نقطه بهینه ننسبت به پارامتر و نسبت به ورودی به دست آورد یعنی:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-reaction",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\text{ift :} \\ \\  S(p) = \\{x | g(x,p)=0\\} \\Rightarrow D_p S(p) = -D_x g(p, S(p))^{-1} D_p g(p, S(p))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-subdivision",
   "metadata": {},
   "source": [
    "حال اگر در نقطه بهینه $g( \\bar x, \\bar \\theta)$ ما $\\bar x$ را به عنوان پارامتر در نظر بگیریم $S(\\bar x) = \\bar \\theta$ می شود و برای بدست آوردن مشتق $\\bar \\theta$ به نسبت ورودی به جای عبور گرادیان از کل مسیر بهینه سازی از ift استفاده میکنیم:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-arrival",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "D_{\\bar x} \\bar \\theta = -D_{\\theta} g(\\bar x, \\bar \\theta)^{-1} D_{\\bar x} g(\\bar x, \\bar \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-attribute",
   "metadata": {},
   "source": [
    "همانطور که دیده می شود گرادیان ورودی به صورت فرم بسته در نقطه نهایی بهینه سازی محاسبه شده و نیازی به عبور دادن گرادیان از مسیر بهینه سازی نیست."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-thread",
   "metadata": {},
   "source": [
    "ج) می دانیم برای گنجاندن linear regression در قالب راه حل svm می توان از least-square SVM ها مانند Kernel Ridge Regression استفاده کرد. البته برای مساله دسته بندی چند کلاسه می توان از تابع هزینه Hinge چند کلاسه نیز استفاده کرد. برای Ridge Regression می توان دستگاه زیر را حل کرد: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-phoenix",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\phi = \\mathcal Alg(D_train, \\theta) = arg \\min_{w_k, \\zeta_i} \\frac{1}{2} \\sum_k \\lVert w_k \\rVert_{2}^{2} + C\\sum_n \\zeta_{n}^{2} \\ \\ \\ \\ \\text{ s.t. } \\ \\ \\ w_{y_n}f_{\\theta}(x_n) - y_n = \\zeta_n  \\ \\ \\ \\forall k,n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-florist",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\mathcal L = \\frac{1}{2} \\sum_k \\lVert w_k \\rVert_{2}^{2} + C\\sum_n \\zeta_{n}^{2} + \\sum_{n} \\alpha^{y_n} [ w_{y_n}f_{\\theta}(x_n) - y_n - \\zeta_n ] \\\\ \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-permission",
   "metadata": {},
   "source": [
    "البته دستگاه بالا با فرض one-hot بودن لیبل ها نیست. برای دسته بندی باید از تابع هزینه Hinge و لیبل های One-hot استفاده کرد که در مقاله نیز ذکر شده است. با اعمال تغییرات لازم فرم دوگان دستگاه بالا با مشتق گرفتن نسبت به متغیر ها و جاگذاری و حذف متغیر های primal به شکل زیر است:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-uruguay",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "\\max_{\\alpha^k} [ -\\frac{1}{2}\\sum_k \\lVert w_k(\\alpha^k) \\rVert_{2}^{2} - \\frac{\\lambda}{2} \\sum_k \\lVert \\alpha^k \\rVert_{2}^{2} + \\sum_n \\alpha_{n}^{y_n} ]  \\ \\ \\ \\text{where}  \\ \\ \\ w_k(\\alpha^k) = \\sum_k \\alpha_{n}^{k} f_{\\theta}(x_n)\\\\\n",
    "s.t. \\ \\ \\ \\alpha_{n}^{y} \\leq C\\delta(y,y_n) \\ \\ \\ \\text{and}\\ \\ \\ \\ \\sum_k \\alpha_{k}^{n} = 0 \\ \\ \\ \\ \\ \\forall n,y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-people",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "د) در این مساله متا-پارامتر های $\\theta$ پارامتر های شبکه backbone و پارامتر های سریع یا $\\phi$ همان وزن های کلاس های مختلف($w_k$) در SVM یا Kernel Ridge Regression هستند که از فرآیند بهینه سازی QP روی فیچر ها استخراج شده از ورودی توسط متاپارامتر بدست می آیند. طبق روال svm یا رگرسیون وزن تابع امتیاز ضرب وزن کلاس در فیچر های ورودی است. فرمول محاسبه هزینه روی داده های متا تست بالاتر نوشته شده است. اگر برای درست نمایی از تابع softmax استفاده کنیم می توان تابع هزینه را به کمک منفی لگاریتم درست نمایی به شکل زیر نشان داد:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-dancing",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "Objective: \\min_{\\theta} E_{\\mathrm{T}} [\\mathcal L^{meta} (D^{test}; \\theta, \\phi), \\ \\ \\text{where} \\ \\  \\phi = \\mathcal A(D^{train}, \\theta)] \\\\\n",
    "\\mathcal L^{meta} (D^{test}; \\theta, \\phi) = E_{(x,y) \\sim D^{test}} [-\\log(\\frac{ \\exp(\\phi_y f_{\\theta}(x)) }{ \\sum_k \\exp(\\phi_k f_{\\theta}(x)) })] = \\sum_{(x,y) \\sim D^{test}} [-w_yf_{\\theta}(x) + \\log\\sum_k \\exp(w_k f_{\\theta}(x))]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-karen",
   "metadata": {},
   "source": [
    "که با برگرداندن گرادیان هزینه بالا به نسبت متاپارامتر های $\\theta$ که دیده شد در صورت استفاده از یک فرآیند بهینه سازی محدب به عنوان adaptation می توان اغلب عبور گرادیان از فرآیند را دور زد، وزن های شبکه استخراج ویژگی backbone متا-آموزش داده می شوند. البته در مقاله ذکر شده است که با استناد به ممقالات دیگر استفاده از یک پارامتر دیگر به عنوان ضریب برای scale کردن score ها می تواند موثر باشد."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-colon",
   "metadata": {},
   "source": [
    "# سوال ۴\n",
    "\n",
    "الف) در مقاله اشاره شده راه حلی که برای حل کشیدگی داده ها استفاده می شود Tukey's Ladder نام دارد. در این روش که از پولینومیال رگرشن الهام گرفته شده است از یک تبدیل توانی به فرم $x^{'} = x^\\lambda$  استفاده می شود که از $\\lambda$ برای تنظیم کشیدگی استفاده می شود. برای مقادیر مثبت و با افزایش هایپرپارامتر $\\lambda$ مقادیر بزرگ تر بیشتر از مقادیر کوچک تشدید می شوند در نتیجه کشیدگی مثبت نمودار افزایش داده می شود در نتیجه مقادیر مثبت برای کاهش دادن کشیدگی منفی (سمت چپ) مناسب است. به طور عکس برای مقادیر منفی و با کاهش هایپرپارامتر، مقادیر بزرگ تر بیشتر از مقادیر کوچک تضعیف می شوند و کشیدگی منفی افزایش می یابد در نتیجه برای جبران کشیدگی راست مناسب اند. البته این روش یک سری نرمال سازی نیاز دارد مانند استفاده از log در حالتی که $\\lambda=0$ است یا استفاده از یک ضریب منفی با توجه به رابطه ی علامت داده ها و علامت هایپرپارامتر (یا بزرگتر و کوچکتر بودن از یک آنها) برای حفظ ترتیب داده ها و قرینه نشدن آنها یا استفاده از فرم $x^{'} = a_0 + a_1x^\\lambda$   (که از a_0 و  a_1 برای تنظیم میانگین و واریانس استفاده می شود) برای جابه جایی داده ها برای حفظ ترتیب بعد از تبدیل توانی. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-personal",
   "metadata": {},
   "source": [
    "ب) در این مساله فرض می شود دیتاست از یک سری کلاس پایه و یک سری کلاس جدید تشکیل شده است. هدف این است که یک مدل روی کلاس های پایه آموزش داده شود تا مدل روی کلاس های جدید قابلیت تعمیم بالایی داشته باشد. برای بررسی تعمیم پذیری مدل روی کلاس های جدید در ستینگ Few Shot بررسی می شوند و عملکرد مدل روی کلاس های جدید با میانگین عملکرد ان روی اپیزود های مختلف ایجاد شده از کلاس های جدید سنجیده می شود. فرض می شود از کلاس های پایه به اندازه خوبی داده داریم بر خلاف اپیزود های (فرضی) ایجاد شده از کلاس های جدید. در نتیجه آماره هایی که از داده های کلاس ها پایه داریم دقیق تر هستند. شهود مقاله این است که اگر معیاری برای تشابه آماره های کلاس های پایه و جدید در نظر بگیریم، می توانیم از آماره های دقیق بدست آمده از کلاس های پایه برای افزایش دقت آماره های ضعیف کلاس های جدید که دیتای کم دارند استفاده کرد.\n",
    "\n",
    "مراحل الگوریتم به شکل زیر است: (ابتدا یک روش متفاوت با مقاله توضیح داده می شود سپس در قسمت بعدی دلیل تفاوت مقاله با روش ابتدایی توضیح داده می شود)\n",
    "\n",
    "\n",
    "ابتدا برای هر کلاس داده های ساپورت با میانگین $\\mu$ بعد از تبدیل توانی، فاصله میانیگن اش از میانگین توزیع کلاس های پایه محاسبه می شود (D) و سپس k کلاس که این کلاس جدید بیشترین نزدیکی به میانگین آنها را دارد انتخاب می شوند ($S_y$). سپس میانگین کالیبره شده ی کلاس جدید با میانگین گرفتن از میانگین کلاس جدید و K کلاس پایه محاسبه می شود. همچنین کواریانس نیز به همین شکل (البته در محاسبه کواریانس فقط از آماره های کلاس های پایه استفاده می شود زیرا در مقاله توزیع برای تک داده ها محاسبه می شود)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-houston",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "D = \\{ - \\lVert \\mu_i - \\mu \\rVert^2 | i \\in C_b \\} \\\\\n",
    "S_y = \\{ i | - \\lVert \\mu_i - \\mu \\rVert^2 \\in topk(D) \\} \\\\\n",
    "\\mu^\\prime = \\frac{ \\sum_{i \\in S_N} \\mu_i + \\mu }{K+1}, \\ \\ \\ \\Sigma^\\prime = \\frac{ \\sum_{i \\in S_N} \\Sigma_i + \\Sigma }{K+1} + \\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-charity",
   "metadata": {},
   "source": [
    "سپس در زمان اداپتیشن (در مقاله ذکر نشده که در زمان متا ترین یا متا تست اما احتمالا فقط  به ساپورت های متا ترین اضافه شده تا در زمان متا تست تعمیم پذیری مدل متا-ترین شده با فیچر های منتقل شده از کلاس های پایه روی دیتای ساپورت کوچک متا-تست بررسی شود) از دیستریبیوشن جدید بدست آمده تعداد مناسبی (در مقاله ۷۵۰) نمونه گرفته شده و به مجموعه کوچک پشتیبان اولیه اضافه شده. سپس یک دسته بند روی این ساپورت جدید آموزش داده می شود."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-domain",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "D_y = \\{ (x,y) | x  \\sim  N(\\mu^{\\prime}_{y}, \\Sigma^{\\prime}_{y}) \\} \\\\\n",
    "\\mathcal l = \\sum_{(x,y) \\sim S^{\\lambda-transformed} \\cup D_y} - \\log Pr(y|x, \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-discrimination",
   "metadata": {},
   "source": [
    "انتظار می رود اگر داده های ساپورت اولیه زیاد نویزی نباشند با تبدیل توانی به یک توزیع گاوسی نزدیک شوند، سپس به کمک آماره های با دقت بالای بدست آمده از کلاس های پایه و انتخاب مناسب K، اگر کلاس های نزدیک به کلاس جدید در K کلاس پایه مشابه وجود داشته باشند با کالیبره کردن آماره های نادقیق کلاس های جدید با آماره های کلاس های پایه، این توزیع ها به توزیع های واقعی این کلاس ها نزدیک تر شوند. در این صورت با افزایش تعداد داده های پشتیبان (مثلا از ۵ به ۷۵۰) که از این توزیع های دقیق تر بدست آمده اند نه تنها دقت دسته بند ها کاهش نیابد  بلکه افزایش یافته و قدرت تعمیم پذیری مدل متا یادگرفته شده با وجود دیتای کم به کمک دیتا های ساختگی گرفته شده از آماره های منتقل شده افزایش نیز بیابد. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-kazakhstan",
   "metadata": {},
   "source": [
    "ج) راه حل قسمت گذشته ممکن است در ستینگ فیو شات مشکل آفرین باشد. زیرا در این تعداد داده کم ممکن است آماره های ابتدایی کلاس های جدید به دلییل وجود حتی یک داده نویزی بسیار دور از واقعیت باشند و انتقال آماره ها نیر نتواند این مشکل را جبران کند ( چون ممکن است اگر K بالا باشد کلاس های غیر مشابه زیاد اجازه کالیبراسیون ندهن یا مثلا K کم باشد که در اینصورت کالیبراسیون بسیار شدید نیست). در این صورت برای حذف بایاس حاصل از یک داده یا زیر مجموعه ای خاص از داده ها، در مرحله کالیبراسیون به جای استفاده از میانگین داده های پشتیبان از تک تک داده های استفاده شده و برای هر داده ساپورت ($x_i, \\ \\ i \\in \\{1, ..., K\\} $) یک توزیع $D_i$ بدست می آید و تعداد بیشتری توزیع کالیبره شده بر اساس تک تک نمونه ها گرفته می شود. سپس از همه توزیع ها به تعداد مساوی نمونه گرفته می شود. در این صورت یک توزیع Mixture با پراکندگی و پوشش وسیع تر و احتمالا دقیق تر بدست می آید. زیرا مثلا یک داده نویزی اگر توزیعش هم خیلی پرت باشد که نیست چون تا حدی آن هم کالیبره می شود، فقط در کسری از داده ها برای نمونه گیری استفاده می شود و توزیع کلی را زیاد به هم نمی ریزد و در بدترین حالت نویزی که ایجاد میکند به اندازه نویز در داده های ساپورت اولیه است و نتیجه بدتر نمی شود) به طور خلاصه:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-celtic",
   "metadata": {
    "direction": "ltr"
   },
   "source": [
    "$$\n",
    "D_j = \\{ - \\lVert \\mu_i - \\tilde x_j \\rVert^2 | i \\in C_b \\} \\\\\n",
    "S_{j,y} = \\{ i | - \\lVert \\mu_i - \\tilde x_j \\rVert^2 \\in topk(D) \\} \\\\\n",
    "\\mu{^\\prime}_{j} = \\frac{ \\sum_{i \\in S_N} \\mu_i + \\tilde x_j }{K+1}, \\ \\ \\ \\Sigma^{\\prime}_{j} = \\frac{ \\sum_{i \\in S_N} \\Sigma_i }{K} + \\alpha \\\\\n",
    "S_y = \\{ N(\\mu^{\\prime}_{y}, \\Sigma^{\\prime}_{1}), ..., N(\\mu^{\\prime}_{K}, \\Sigma^{\\prime}_{K})  \\} \\\\\n",
    "D_y = \\{ (x,y) | x  \\sim  N(\\mu, \\Sigma), \\forall (\\mu,\\Sigma) \\in S_y \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-resource",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "direction": "rtl",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
